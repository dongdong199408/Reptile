{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import lxml\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import m3u8\n",
    "\n",
    "class ViedeoCrawler():\n",
    "    def __init__(self):\n",
    "        self.url = \"\"\n",
    "        self.down_path = r\"D:\\News\"\n",
    "        self.final_path = r\"D:\\News\"\n",
    "        try:\n",
    "            self.name = re.findall(r'/[A-Za-z]*-[0-9]*',self.url)[0][1:]\n",
    "        except:\n",
    "            self.name = \"uncensord\"\n",
    "        self.headers = {\n",
    "            'Connection': 'Keep-Alive',\n",
    "            'Accept': 'text/html, application/xhtml+xml, */*',\n",
    "            'Accept-Language': 'en-US,en;q=0.8,zh-Hans-CN;q=0.5,zh-Hans;q=0.3',\n",
    "            'User-Agent':'Mozilla/5.0 (Linux; U; Android 6.0; zh-CN; MZ-m2 note Build/MRA58K) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/40.0.2214.89 MZBrowser/6.5.506 UWS/2.10.1.22 Mobile Safari/537.36'\n",
    "        }\n",
    "\n",
    "    def get_ip_list(self):\n",
    "        print(\"正在获取代理列表...\")\n",
    "        url = 'http://www.xicidaili.com/nn/'\n",
    "        html = requests.get(url=url, headers=self.headers).text\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        ips = soup.find(id='ip_list').find_all('tr')\n",
    "        ip_list = []\n",
    "        for i in range(1, len(ips)):\n",
    "            ip_info = ips[i]\n",
    "            tds = ip_info.find_all('td')\n",
    "            ip_list.append(tds[1].text + ':' + tds[2].text)\n",
    "        print(\"代理列表抓取成功.\")\n",
    "        return ip_list\n",
    "\n",
    "    def get_random_ip(self,ip_list):\n",
    "        print(\"正在设置随机代理...\")\n",
    "        proxy_list = []\n",
    "        for ip in ip_list:\n",
    "            proxy_list.append('http://' + ip)\n",
    "        proxy_ip = random.choice(proxy_list)\n",
    "        proxies = {'http': proxy_ip}\n",
    "        print(\"代理设置成功.\")\n",
    "        return proxies\n",
    "\n",
    "    def get_uri_from_m3u8(self,realAdr):\n",
    "        print(\"正在解析真实下载地址...\")\n",
    "        with open('temp.m3u8', 'wb') as file:\n",
    "            file.write(requests.get(realAdr).content)\n",
    "        m3u8Obj = m3u8.load('temp.m3u8')\n",
    "        print(\"解析完成.\")\n",
    "        return m3u8Obj.segments\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Start!\")\n",
    "        start_time = time.time()\n",
    "        os.chdir(self.down_path)\n",
    "        html = requests.get(self.url).text\n",
    "        bsObj = BeautifulSoup(html, 'lxml')\n",
    "        realAdr = bsObj.find(id=\"video-player\").find(\"source\")['src']\n",
    "\n",
    "        # duration = bsObj.find('meta', {'property': \"video:duration\"})['content'].replace(\"\\\"\", \"\")\n",
    "        # limit = int(duration) // 10 + 3\n",
    "\n",
    "        ip_list = self.get_ip_list()\n",
    "        proxies = self.get_random_ip(ip_list)\n",
    "        uriList = self.get_uri_from_m3u8(realAdr)\n",
    "        i = 1   # count\n",
    "        for key in uriList:\n",
    "            if i%50==0:\n",
    "                print(\"休眠10s\")\n",
    "                time.sleep(10)\n",
    "            if i%120==0:\n",
    "                print(\"更换代理IP\")\n",
    "                proxies = self.get_random_ip(ip_list)\n",
    "            try:\n",
    "                resp = requests.get(key.uri, headers = self.headers, proxies=proxies)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                return\n",
    "            if i < 10:\n",
    "                name = ('clip00%d.ts' % i)\n",
    "            elif i > 100:\n",
    "                name = ('clip%d.ts' % i)\n",
    "            else:\n",
    "                name = ('clip0%d.ts' % i)\n",
    "            with open(name,'wb') as f:\n",
    "                f.write(resp.content)\n",
    "                print('正在下载clip%d' % i)\n",
    "            i = i+1\n",
    "        print(\"下载完成！总共耗时 %d s\" % (time.time()-start_time))\n",
    "        print(\"接下来进行合并……\")\n",
    "        os.system('copy/b %s\\\\*.ts %s\\\\%s.ts' % (self.down_path,self.final_path, self.name))\n",
    "        print(\"合并完成，请您欣赏！\")\n",
    "        y = input(\"请检查文件完整性，并确认是否要删除碎片源文件？(y/n)\")\n",
    "        if y=='y':\n",
    "            files = os.listdir(self.down_path)\n",
    "            for filena in files:\n",
    "                del_file = self.down_path + '\\\\' + filena\n",
    "                os.remove(del_file)\n",
    "            print(\"碎片文件已经删除完成\")\n",
    "        else:\n",
    "            print(\"不删除，程序结束。\")\n",
    "\n",
    "if __name__=='__main__':\n",
    "    crawler = ViedeoCrawler()\n",
    "    crawler.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
